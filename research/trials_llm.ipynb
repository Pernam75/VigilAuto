{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/jules/Documents/GithubRepo/VigilAutoAgent\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/Users/jules/Documents/GithubRepo/VigilAutoAgent'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%cd ..\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY7QjWRKZMrT",
        "outputId": "c6147cfe-eb40-486e-8518-fbd86951e3f4"
      },
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wTJl4KecZQ--"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RvEmVS1yZQ5l"
      },
      "outputs": [],
      "source": [
        "chat = ChatGroq(temperature=0, groq_api_key=GROQ_API_KEY, model_name=\"mixtral-8x7b-32768\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gReDcWzeZa1f",
        "outputId": "d42de8b5-6fa0-4372-89ec-b3be5b5bbbe8"
      },
      "outputs": [],
      "source": [
        "def get_response(human_entry: str) -> str:\n",
        "    \"\"\"\n",
        "    * human_entry: str\n",
        "    * return: str\n",
        "\n",
        "    This function takes a human entry and returns the response from the model.\n",
        "\n",
        "    TODO : Add the alccol level in the prompt and announce it to the driver if it is above 0.5g/L\n",
        "    \n",
        "    \"\"\"\n",
        "    SYSTEM_PROMPT = \"Tu es un assistant vocal de conduite. Grâce à une caméra intégrée dans la voiture, le taux d'alcoolémie du conducteur est mesuré. Sache qu'un verre standard d'alccol équivault à 0.2g/L. Si le taux est supérieur à 0.5g/L, tu dois conseiller au conducteur de ne pas conduire. Reste concis dans tes réponses. Elles ne doivent pas dépasser deux courtes phrases\"\n",
        "    human = \"{text}\"\n",
        "    alcool = 1.6\n",
        "    prompt = ChatPromptTemplate.from_messages([(\"system\", SYSTEM_PROMPT), (\"human\", human)])\n",
        "\n",
        "    chain = prompt | chat\n",
        "    result = chain.invoke({\"text\": human_entry})\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Je suis désolé, mais votre taux d'alcoolémie est de 0.____ g/L. Je vous conseille de ne pas conduire.\n"
          ]
        }
      ],
      "source": [
        "human_text = \"J'ai bu quelques verres, mais je me sens bien pour conduire.\"\n",
        "result = get_response(human_text)\n",
        "print(result.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
