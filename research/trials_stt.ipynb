{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jules/Documents/GithubRepo/VigilAutoAgent\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/jules/Documents/GithubRepo/VigilAutoAgent'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%cd ..\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai-whisper in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (20231117)\n",
      "Requirement already satisfied: numba in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from openai-whisper) (0.59.1)\n",
      "Requirement already satisfied: numpy in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from openai-whisper) (2.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from openai-whisper) (4.66.2)\n",
      "Requirement already satisfied: more-itertools in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from openai-whisper) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from openai-whisper) (0.6.0)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from numba->openai-whisper) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from tiktoken->openai-whisper) (2.31.0)\n",
      "Requirement already satisfied: filelock in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from torch->openai-whisper) (3.13.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from torch->openai-whisper) (4.10.0)\n",
      "Requirement already satisfied: sympy in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from torch->openai-whisper) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from torch->openai-whisper) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from torch->openai-whisper) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from torch->openai-whisper) (2024.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U openai-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages/whisper/__init__.py:65: UserWarning: /Users/jules/.cache/whisper/tiny.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████| 72.1M/72.1M [00:09<00:00, 7.60MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "model = whisper.load_model(\"tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/vigilauto/lib/python3.10/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The text in video: \n",
      "  Bonjour, as-y comme un agent et empêche-moi de conduire. D'accord, dans ce cas je vous dirais, pour votre sécurité et celle des autres sur la route, je dois vous demander de ne pas conduire maintenant. C'est important de prendre des décisions responsables quand il s'agit de conduite. Et attendez une raison particulière pour laquelle vous envisagez le conduire qui vous préoccupent.\n"
     ]
    }
   ],
   "source": [
    "result = model.transcribe(\"record.mp4\")\n",
    "print(f' The text in video: \\n {result[\"text\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vigilauto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
